{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744674e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from config import api_key_inCites\n",
    "from config import api_key_WOS\n",
    "import clarivate.wos_journals.client\n",
    "from clarivate.wos_journals.client.api import journals_api\n",
    "from clarivate.wos_journals.client.model.journal_list import JournalList\n",
    "from pprint import pprint\n",
    "\n",
    "## Pip install the Clarivate Journal Client\n",
    "## pip install git+https://github.com/clarivate/wosjournals-python-client.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print files in current dirctory\n",
    "for i in os.listdir('./'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a68637",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this to SQL query in Elements Reporting Database for faculty publication data\n",
    "## https://github.com/kglibrarian/symplecticelementssql/blob/master/Data%20Source%20Publication%20IDs%20Report%20by%20Group%20of%20Authors.md\n",
    "\n",
    "## Upload the resulting .csv from Elements\n",
    "\n",
    "elements_data_path = \"data/2023_01-12_FSM_Pubs_2018_to_2022.csv\"\n",
    "\n",
    "## Read the CSV file and store into Pandas DataFrame \n",
    "elements_data_df = pd.read_csv(elements_data_path, encoding = \"ISO-8859-1\")\n",
    "## encoding = \"ISO-8859-1\", na_values=['NULL', '<NA>']\n",
    "\n",
    "#Change the column names to lower case with underscore for spaces\n",
    "elements_data_df.columns =  elements_data_df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"ï»¿\",\"\")\n",
    "elements_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the length of the dataframe (i.e. how many rows)\n",
    "print(\"Number of rows in the dataframe: \", len(elements_data_df.index))\n",
    "\n",
    "## Check how many nans are in each column\n",
    "elements_data_df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75335a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a column based on year\n",
    "## 1. Change publication_date column from object to a datetime format\n",
    "elements_data_df['publication_date'] = pd.to_datetime(elements_data_df['publication_date'], format='%m/%d/%Y')\n",
    "\n",
    "## 2. Extract year and create new column from publication_date\n",
    "elements_data_df['year'] = elements_data_df['publication_date'].dt.year \n",
    "elements_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba842a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize how many faculty have published in a journal by year\n",
    "## Make a new dataframe with subset of data, including user_id, publication_id, issn, eissn, and year\n",
    "## Our backbone ID is the eissn, and then also year\n",
    "## a) If publication ID is listed more than once for each journal in each year, we only want to count it once. \n",
    "## b) If user ID is listed more than once for each journal in each year, we only want to count it once.\n",
    "\n",
    "unique_publications_df = elements_data_df.groupby(['year', 'eissn']).agg({'publication_id': 'nunique', \n",
    "                                                                          'user_id':'nunique' }).rename(columns={'publication_id': 'Count of Unique Publications',\n",
    "                                                                                                                'user_id': 'Count of Unique Authors'})\n",
    "unique_publications_df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5284ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset the index so year and eissn are columns\n",
    "unique_publications_df.reset_index(level=['year','eissn'], inplace=True)\n",
    "unique_publications_df.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847976ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize across 5 years how many unique faculty have published in a journal\n",
    "\n",
    "unique_publications_all_df = elements_data_df.groupby(['eissn']).agg({'publication_id': 'nunique', \n",
    "                                                                          'user_id':'nunique' }).rename(columns={'publication_id': 'Count of Unique Publications 2018-2022',\n",
    "                                                                                                                'user_id': 'Count of Unique Authors 2018-2022'})\n",
    "unique_publications_all_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea43841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pivot so that the data is provided by Year\n",
    "\n",
    "pivot_unique_publications_df = unique_publications_df.pivot(index='eissn', columns='year', values=['Count of Unique Publications', 'Count of Unique Authors'])\n",
    "pivot_unique_publications_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flatten the column names \n",
    "pivot_unique_publications_df.columns = [f\"{x}_{y}\" for x, y in pivot_unique_publications_df.columns.to_flat_index()]\n",
    "pivot_unique_publications_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify the column names\n",
    "# iterating the columns\n",
    "for col in pivot_unique_publications_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum publication columns for 5 year totals\n",
    "\n",
    "# pivot_unique_publications_df['Count of Unique Publications 2018-2022'] = pivot_unique_publications_df.loc[:, \"Count of Unique Publications_2018\":\"Count of Unique Publications_2022\"].sum(axis=1)\n",
    "# pivot_unique_publications_df.head(50)\n",
    "\n",
    "# df['variance'] = df.loc[:,['budget','actual']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload the .csv from CMMS of Top ILL & Turnaways\n",
    "\n",
    "cmms_data_path = \"data/2023_Top ILL & Turnaways.csv\"\n",
    "\n",
    "## Read the CSV file and store into Pandas DataFrame \n",
    "cmms_data_df = pd.read_csv(cmms_data_path, encoding = \"ISO-8859-1\")\n",
    "## encoding = \"ISO-8859-1\", na_values=['NULL', '<NA>']\n",
    "\n",
    "#Change the column names to lower case with underscore for spaces\n",
    "cmms_data_df.columns =  cmms_data_df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"ï»¿\",\"\")\n",
    "cmms_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e47076",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the length of the dataframe (i.e. how many rows)\n",
    "print(\"Number of rows in the dataframe: \", len(cmms_data_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(cmms_data_df, pivot_unique_publications_df, left_on='electronic_issn', right_index=True, how=\"left\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f724197",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the length of the dataframe (i.e. how many rows)\n",
    "print(\"Number of rows in the dataframe: \", len(merged_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge with yearly totals\n",
    "\n",
    "merged_2_df = pd.merge(merged_df, unique_publications_all_df, left_on='electronic_issn', right_index=True, how=\"left\")\n",
    "merged_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc409538",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the length of the dataframe (i.e. how many rows)\n",
    "print(\"Number of rows in the dataframe: \", len(merged_2_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba06d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataframe to a CSV\n",
    "\n",
    "with open(r\"output/merged_2_df.csv\", 'w', encoding='utf-8') as file:\n",
    "    merged_2_df.to_csv(file, line_terminator='\\n', index=True)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b467ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
